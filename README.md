# ASR (Automatic Speech Recognition) Application
## Кейс: ASR (Automatic speech recognition – автоматическое распознавание речи)
## Задача 1.

### Описание проекта
Веб-приложение для автоматического распознавания речи (ASR), предоставляющее следующие возможности:
1. Транскрипция аудио в текст.
2. Диаризация (разделение аудио по спикерам).
3. Генерация сеанса транскрипции (субтитров) в режиме реального времени.

---

### Установка и запуск
#### Требования
- **Оборудование**:
  - GPU: NVIDIA GeForce RTX 4070 или выше (рекомендуется для ускорения работы).
  - CPU: возможно использование, но скорость обработки будет ниже.
- **Colab**: решение можно также запустить на Google Colab [по этой ссылке](https://colab.research.google.com/drive/1kCXscE3GLK1CPpmD548z-WyG0UtAS9-t?usp=sharing).

---

### Использованный стек
- **Python**: основной язык программирования.
- **Flask**: фреймворк для создания веб-приложений.
- **Whisper**: модель для автоматического распознавания речи.
- **PyAnnote.Audio**: библиотека для диаризации.
- **Librosa** и **Soundfile**: для предварительной обработки аудиофайлов.
- **HTML, CSS, JavaScript**: для создания пользовательского интерфейса.

---

### Основные возможности
1. **Транскрипция речи**:
   - Преобразование речи в текст с высокой точностью.
   - Поддержка русского языка.

2. **Диаризация**:
   - Определение границ речи каждого спикера.
   - Формирование сегментов с указанием спикера и времени.

3. **Генерация сеанса транскрипции**:
   - Создание субтитров в формате SRT.
   - Точность временной привязки.

---

### Используемые алгоритмы и методы

#### 1. **Транскрипция речи (Whisper)**
Для распознавания речи используется модель **Whisper** от OpenAI:
- **Алгоритм**: Whisper основан на архитектуре трансформеров, которая позволяет эффективно анализировать временные ряды данных, такие как звук. Модель обучена на больших объемах многоязычных данных, что обеспечивает высокую точность транскрипции.
- **Методы**:
  - Модель принимает входной аудиофайл, преобразованный в частотный спектр с помощью STFT (Short-Time Fourier Transform).
  - Производится предварительная обработка данных для нормализации громкости и устранения шумов.
  - Выходом модели является текстовая расшифровка аудиофайла.

---

#### 2. **Диаризация речи (PyAnnote.Audio)**
Для разделения речи по спикерам применяется **PyAnnote.Audio**:
- **Алгоритм**: Модель использует предобученные нейронные сети для анализа акустических характеристик и выделения сегментов, принадлежащих различным спикерам.
- **Методы**:
  - Сначала выполняется сегментация речи: определяются интервалы, содержащие голосовые данные.
  - Затем на основе акустических признаков каждому сегменту присваивается уникальный идентификатор спикера.
  - Итогом является список временных интервалов с указанием спикера.

---

#### 3. **Предварительная обработка аудио**
Аудиофайлы нормализуются и ресемплируются с помощью библиотек **Librosa** и **Soundfile**:
- **Алгоритм**:
  - Сначала аудиофайл загружается с использованием Librosa, где происходит нормализация амплитуды.
  - Затем файл ресемплируется до фиксированной частоты дискретизации (16 кГц), что требуется для корректной работы моделей.
  - Обработанный файл сохраняется в формате WAV.
- **Методы**:
  - Используется метод `librosa.load` для загрузки файла и его ресемплирования.
  - Сохранение в нужном формате осуществляется с помощью `soundfile.write`.

---

#### 4. **Генерация субтитров**
Для создания субтитров в формате SRT используются временные метки, предоставленные моделью Whisper:
- **Алгоритм**:
  - Каждая текстовая транскрипция содержит временные отметки начала и конца сегмента.
  - На основе этих данных формируется текст в формате SRT.
- **Методы**:
  - Функция `generate_srt` конвертирует временные метки в формат `hh:mm:ss,ms` и сопоставляет их с текстовыми данными.


### Итог
Использованные алгоритмы и методы обеспечивают высокую точность и удобство работы с аудиофайлами. Благодаря мощным библиотекам Whisper и PyAnnote.Audio, приложение способно решать широкий спектр задач ASR, включая диаризацию, транскрипцию и создание субтитров. Предварительная обработка данных гарантирует корректность и стабильность работы всех компонентов.