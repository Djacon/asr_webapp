{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y561dh2-b_wa"
      },
      "source": [
        "# Кейс: ASR (Automatic speech recognition – автоматическое распознавание речи)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Скачиваем необходимые библиотеки/фреймворки"
      ],
      "metadata": {
        "id": "xOte8WkMVBVw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai-whisper flask ffmpeg-python\n",
        "!apt-get install ffmpeg\n",
        "!pip install pyngrok"
      ],
      "metadata": {
        "id": "c8U5CBReBo7_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -q -O ngrok.zip https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "!unzip -o ngrok.zip"
      ],
      "metadata": {
        "id": "Sly9nB45Bo5p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ngrok config add-authtoken 2qAfdhGGhliui7cmzQLZRwCzxRj_69brrS9x4NzVqhGovD72K"
      ],
      "metadata": {
        "id": "0Pz4vEOfBo3H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install SpeechRecognition"
      ],
      "metadata": {
        "id": "okIG_4-PBwlR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyannote.audio"
      ],
      "metadata": {
        "id": "juia1cvsBwi9",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install websockets"
      ],
      "metadata": {
        "id": "nUcK-3yQBo0t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7uYdIa12EDug"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Загружаем модели и создаем сайт на Flask"
      ],
      "metadata": {
        "id": "E6RTNm5AVK8W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import whisper\n",
        "from flask import Flask, request, jsonify, render_template, Response, send_file\n",
        "from pyannote.audio import Pipeline\n",
        "import librosa\n",
        "import soundfile as sf\n",
        "import threading\n",
        "import time\n",
        "import torch\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "\"\"\"\n",
        "Подключение токена HuggingFace\n",
        "Для корректной работы приложения необходимо подключить свой токен HuggingFace.\n",
        "Обратите внимание, что для использования моделей требуется наличие доступов (грантов) к следующим репозиториям:\n",
        "\n",
        "1. Модель сегментации: https://huggingface.co/pyannote/segmentation\n",
        "2. Модель для диаризации: https://huggingface.co/pyannote/speaker-diarization\n",
        "\n",
        "Пожалуйста, убедитесь, что ваш токен предоставляет соответствующие права доступа к данным моделям.\n",
        "Для подключения токена используется следующий код:\n",
        "\"\"\"\n",
        "from huggingface_hub import notebook_login\n",
        "notebook_login()"
      ],
      "metadata": {
        "id": "8wfX7WFIjWvM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JxeYBDB5ahZV"
      },
      "outputs": [],
      "source": [
        "# Загрузка моделей\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "whisper_model = whisper.load_model(\"tiny\", device=device)\n",
        "pipeline = Pipeline.from_pretrained(\"pyannote/speaker-diarization@2.1\", use_auth_token=True).to(device)\n",
        "\n",
        "\n",
        "def preprocess_audio(input_path, output_path):\n",
        "    \"\"\"Нормализация и ресемплинг аудио\"\"\"\n",
        "    audio, sr = librosa.load(input_path, sr=16000)  # Ресемплинг до 16 кГц\n",
        "    sf.write(output_path, audio, 16000, format='WAV')\n",
        "\n",
        "\n",
        "def perform_diarization(filepath):\n",
        "    \"\"\"Диаризация аудио\"\"\"\n",
        "    print(f\"Performing diarization on {filepath}...\")\n",
        "    diarization = pipeline(filepath)\n",
        "    speaker_segments = []\n",
        "    for turn, _, speaker in diarization.itertracks(yield_label=True):\n",
        "        print(f\"Speaker {speaker}: {turn.start:.1f}s - {turn.end:.1f}s\")\n",
        "        speaker_segments.append(f\"{speaker}: {turn.start:.1f}s - {turn.end:.1f}s\")\n",
        "    return speaker_segments\n",
        "\n",
        "\n",
        "def generate_srt(transcription):\n",
        "    \"\"\"Генерация субтитров в формате SRT\"\"\"\n",
        "    segments = transcription[\"segments\"]\n",
        "    srt_content = \"\"\n",
        "    for idx, segment in enumerate(segments):\n",
        "        start = segment[\"start\"]\n",
        "        end = segment[\"end\"]\n",
        "        text = segment[\"text\"]\n",
        "        srt_content += f\"{idx + 1}\\n{format_time(start)} --> {format_time(end)}\\n{text}\\n\\n\"\n",
        "    return srt_content\n",
        "\n",
        "\n",
        "def format_time(seconds):\n",
        "    \"\"\"Форматирование времени для SRT\"\"\"\n",
        "    millis = int((seconds - int(seconds)) * 1000)\n",
        "    h, m, s = int(seconds // 3600), int((seconds % 3600) // 60), int(seconds % 60)\n",
        "    return f\"{h:02}:{m:02}:{s:02},{millis:03}\"\n",
        "\n",
        "\n",
        "def stream_transcription(filepath):\n",
        "    \"\"\"Постепенная транскрипция для отображения субтитров в реальном времени\"\"\"\n",
        "    try:\n",
        "        # Выполняем транскрипцию сразу\n",
        "        result = whisper_model.transcribe(filepath, task=\"transcribe\", language=\"ru\", fp16=False)\n",
        "\n",
        "        if \"segments\" in result:\n",
        "            for idx, segment in enumerate(result[\"segments\"]):\n",
        "                start = segment['start']\n",
        "                end = segment['end']\n",
        "                text = segment['text']\n",
        "                srt_content = f\"{idx + 1}\\n{format_time(start)} --> {format_time(end)}\\n{text}\\n\\n\"\n",
        "                yield srt_content\n",
        "                time.sleep(end - start)  # Синхронизация с реальным временем\n",
        "        else:\n",
        "            yield f\"data: Ошибка: сегменты не найдены в результате.\\n\\n\"\n",
        "    except Exception as e:\n",
        "        yield f\"data: Ошибка: {str(e)}\\n\\n\"\n",
        "\n",
        "\n",
        "@app.route('/')\n",
        "def index():\n",
        "    return \"\"\"\n",
        "    <!DOCTYPE html>\n",
        "    <html lang=\"en\">\n",
        "    <head>\n",
        "        <meta charset=\"UTF-8\">\n",
        "        <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
        "        <title>ASR App</title>\n",
        "        <style>\n",
        "            body {\n",
        "                font-family: Arial, sans-serif;\n",
        "                margin: 20px;\n",
        "                background-color: #f4f4f9;\n",
        "            }\n",
        "            h1 {\n",
        "                text-align: center;\n",
        "            }\n",
        "            form {\n",
        "                max-width: 400px;\n",
        "                margin: 0 auto;\n",
        "                padding: 20px;\n",
        "                background: white;\n",
        "                border: 1px solid #ddd;\n",
        "                border-radius: 8px;\n",
        "            }\n",
        "            label, select, input, button {\n",
        "                display: block;\n",
        "                width: 100%;\n",
        "                margin-bottom: 10px;\n",
        "            }\n",
        "            button {\n",
        "                background-color: #007BFF;\n",
        "                color: white;\n",
        "                border: none;\n",
        "                padding: 10px;\n",
        "                border-radius: 5px;\n",
        "                cursor: pointer;\n",
        "            }\n",
        "            button:hover {\n",
        "                background-color: #0056b3;\n",
        "            }\n",
        "            #subtitles {\n",
        "                margin-top: 20px;\n",
        "                max-width: 600px;\n",
        "                margin: 20px auto;\n",
        "                padding: 20px;\n",
        "                background: #fff;\n",
        "                border: 1px solid #ddd;\n",
        "                border-radius: 8px;\n",
        "                white-space: pre-wrap;\n",
        "                font-family: monospace;\n",
        "                overflow-y: auto;\n",
        "                height: 200px;\n",
        "            }\n",
        "        </style>\n",
        "    </head>\n",
        "    <body>\n",
        "        <h1>ASR-приложение</h1>\n",
        "        <form action=\"/upload\" method=\"post\" enctype=\"multipart/form-data\">\n",
        "            <label for=\"method\">Выберите метод обработки:</label>\n",
        "            <select name=\"method\">\n",
        "                <option value=\"transcribe\">Транскрипция</option>\n",
        "                <option value=\"diarization\">Диаризация</option>\n",
        "                <option value=\"subtitles\">Субтитры</option>\n",
        "            </select>\n",
        "            <input type=\"file\" name=\"audio_file\" accept=\"audio/*,video/*\">\n",
        "            <button type=\"submit\">Загрузить</button>\n",
        "        </form>\n",
        "        <div id=\"subtitles\"></div>\n",
        "        <script>\n",
        "            const eventSource = new EventSource('/stream_subtitles');\n",
        "            const subtitlesDiv = document.getElementById('subtitles');\n",
        "            const audioElement = document.getElementById('audio');\n",
        "\n",
        "            eventSource.onmessage = function(event) {\n",
        "                subtitlesDiv.textContent += event.data + \"\\n\";\n",
        "                subtitlesDiv.scrollTop = subtitlesDiv.scrollHeight;\n",
        "            };\n",
        "\n",
        "            fetch('/audio')\n",
        "                .then(response => response.blob())\n",
        "                .then(blob => {\n",
        "                    const url = URL.createObjectURL(blob);\n",
        "                    audioElement.src = url;\n",
        "                })\n",
        "                .catch(error => console.error('Ошибка загрузки аудио:', error));\n",
        "\n",
        "            audioElement.addEventListener('play', () => {\n",
        "                eventSource.onmessage = function(event) {\n",
        "                    const [timeRange, text] = event.data.split(' ', 2);\n",
        "                    const [start, end] = timeRange.split('-').map(parseFloat);\n",
        "\n",
        "                    const currentTime = audioElement.currentTime;\n",
        "                    if (currentTime >= start && currentTime <= end) {\n",
        "                        subtitlesDiv.textContent += text + \"\\n\";\n",
        "                        subtitlesDiv.scrollTop = subtitlesDiv.scrollHeight;\n",
        "                    }\n",
        "                };\n",
        "            });\n",
        "        </script>\n",
        "    </body>\n",
        "    </html>\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "@app.route('/upload', methods=['POST'])\n",
        "def upload():\n",
        "    if 'audio_file' not in request.files:\n",
        "        return jsonify({\"error\": \"Файл не найден\"}), 400\n",
        "\n",
        "    file = request.files['audio_file']\n",
        "    if file.filename == '':\n",
        "        return jsonify({\"error\": \"Файл не выбран\"}), 400\n",
        "\n",
        "    method = request.form.get(\"method\", \"transcribe\")\n",
        "    filepath = os.path.join(\"uploads\", file.filename)\n",
        "    os.makedirs(\"uploads\", exist_ok=True)\n",
        "    file.save(filepath)\n",
        "\n",
        "    preprocess_audio(filepath, filepath)\n",
        "\n",
        "    if method == \"transcribe\":\n",
        "        try:\n",
        "            result = whisper_model.transcribe(filepath)\n",
        "            os.remove(filepath)\n",
        "            return jsonify({\"text\": result[\"text\"]})\n",
        "        except Exception as e:\n",
        "            return jsonify({\"error\": str(e)}), 500\n",
        "\n",
        "    elif method == \"diarization\":\n",
        "        try:\n",
        "            segments = perform_diarization(filepath)\n",
        "            os.remove(filepath)\n",
        "            return jsonify({\"diarization\": segments})\n",
        "        except Exception as e:\n",
        "            return jsonify({\"error\": str(e)}), 500\n",
        "\n",
        "    elif method == \"subtitles\":\n",
        "      try:\n",
        "        return Response(stream_transcription(filepath), mimetype='text/event-stream')\n",
        "      except Exception as e:\n",
        "        return jsonify({\"error\": str(e)}), 500\n",
        "\n",
        "    else:\n",
        "        return jsonify({\"error\": \"Неверный метод\"}), 400\n",
        "\n",
        "\n",
        "@app.route('/audio')\n",
        "def audio():\n",
        "    \"\"\"Маршрут для потоковой передачи аудио\"\"\"\n",
        "    filepath = os.path.join(\"uploads\", os.listdir(\"uploads\")[0])  # Берем первый файл в папке uploads\n",
        "    return send_file(filepath, mimetype=\"audio/wav\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Запускаем сайт"
      ],
      "metadata": {
        "id": "35w_Z-vnVVCj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JaD3jryac5FL"
      },
      "outputs": [],
      "source": [
        "from pyngrok import ngrok\n",
        "\n",
        "public_url = ngrok.connect(5000)\n",
        "print(f\"Ваше приложение доступно по адресу: {public_url}\\n\")\n",
        "\n",
        "# Запуск Flask\n",
        "app.run(port=5000)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wJDUXiCkE32r"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}